# Tic-Tac-Toe-AI
## ğŸš€ Live Demo
ğŸ‘‰ [Play it here](https://tic-tac-toe-ai-jgfo.onrender.com)
> â³ First load may take ~30 seconds to wake up (free tier)

A Tic Tac Toe game implemented with two AI approaches: <br>
	â€¢	Minimax (perfect-play, deterministic)<br>
	â€¢	Q-Learning (reinforcement learning)<br>


The project allows a human to play against the AI and demonstrates the difference between search-based AI and learning-based AI on a simple game.
---

## Features
	â€¢	Terminal-based Tic Tac Toe game
	â€¢	Human vs AI gameplay
	â€¢	Minimax agent (plays perfectly, never loses)
	â€¢	Q-Learning agent (learns by self-play)
	â€¢	Simple, modular codebase
	â€¢	No heavy libraries required

  ---

  ## Project Structure
  ```
Tic-Tac-Toe-AI/
â”œâ”€â”€ env.py          # Game environment and rules
â”œâ”€â”€ agent.py        # Q-Learning agent
â”œâ”€â”€ train.py        # Training loop for Q-Learning
â”œâ”€â”€ minimax.py      # Minimax agent (perfect play)
â”œâ”€â”€ play.py         # Human vs AI gameplay
â”œâ”€â”€ evaluate.py     # Evaluation utilities
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
## How It Works
1. Environment (env.py)<br>
	â€¢	Manages the board state<br>
	â€¢	Validates moves<br>
	â€¢	Detects wins, draws, and terminal states<br>

2. Minimax Agent (minimax.py)<br>
	â€¢	Explores all possible future moves<br>
	â€¢	Assumes optimal opponent play<br>
	â€¢	Guarantees win or draw<br>
	â€¢	No training required<br>

3. Q-Learning Agent (agent.py, train.py)<br>
	â€¢	Learns stateâ€“action values using rewards<br>
	â€¢	Improves by playing many games<br>
	â€¢	Performance depends on training quality<br>
---

Example Gameplay
```
You are X
Agent is O

X | O | X
---------
O | X | .
---------
. | . | O
```
